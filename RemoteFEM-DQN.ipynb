{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning- and FEM-based Inverse Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Experiment Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/pil-clemson/metamtl-rl/e/METAMTLRL-137\n",
      "Remember to stop your run once youâ€™ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#.stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import neptune.new as neptune\n",
    "\n",
    "os.environ['NEPTUNE_PROJECT']=\"pil-clemson/metamtl-rl\"\n",
    "os.environ['NEPTUNE_NOTEBOOK_ID']=\"45d03d69-6ac7-41ca-8af8-80caaa73aad5\"\n",
    "os.environ['NEPTUNE_NOTEBOOK_PATH']=\"metamaterial-rl/MPFEM-DQN.ipynb\"\n",
    "\n",
    "exp = neptune.init(project=\"pil-clemson/metamtl-rl\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Union, Optional, Callable, Any\n",
    "from typing import Tuple, List, Set, Dict\n",
    "from typing import NamedTuple\n",
    "from typing import Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, deque\n",
    "from types import SimpleNamespace\n",
    "import queue\n",
    "from queue import PriorityQueue\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import multiprocessing\n",
    "import random\n",
    "import math\n",
    "import itertools\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.13.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from torch import Tensor, BoolTensor\n",
    "\n",
    "from torch.nn.modules.loss import _Loss\n",
    "from torch.optim import Optimizer\n",
    "\n",
    "from torchvision.transforms import PILToTensor\n",
    "\n",
    "print('PyTorch version:', torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Cores: 56\n"
     ]
    }
   ],
   "source": [
    "print('CPU Cores:', multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory size: 376 GiB\n"
     ]
    }
   ],
   "source": [
    "# Getting all memory using os.popen()\n",
    "mem_bytes = os.sysconf('SC_PAGE_SIZE') * os.sysconf('SC_PHYS_PAGES')  # e.g. 4015976448\n",
    "mem_gib = mem_bytes/(1024.**3)\n",
    "print('Memory size:', int(mem_gib), 'GiB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs: ['Tesla V100S-PCIE-32GB', 'Tesla V100S-PCIE-32GB']\n"
     ]
    }
   ],
   "source": [
    "available_gpus = [torch.cuda.get_device_name(i) for i in range(torch.cuda.device_count())]\n",
    "print('GPUs:', available_gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current computing device: cpu\n"
     ]
    }
   ],
   "source": [
    "cuda = torch.device('cpu') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print('Current computing device:', cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Batch Logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The Batch Logger logs value of one step without specify the step number every time.\n",
    "Also, steps from all episodes are converted to a log-step, based on the episode and step number. In such case, all steps can be plotted on a single series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchLogger():\n",
    "    def __init__(self, experiment_logger, episode_multiplier: int = 1000) -> None:\n",
    "        self.exp = experiment_logger\n",
    "        self.episode_multiplier: int = episode_multiplier\n",
    "        self.log_step: int = 0\n",
    "    \n",
    "    def step(self, episode: int, step: int) -> None:\n",
    "        self.episode = episode\n",
    "        self.log_step = self.episode_multiplier * episode + step\n",
    "    \n",
    "    def __call__(self, key: str, value: Union[float, str]):\n",
    "        self.exp[key].log(value, step=self.log_step)\n",
    "        \n",
    "    def __setitem__(self, key: str, value: Union[float, str]):\n",
    "        self.exp[key].log(value, step=self.log_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = BatchLogger(exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameters():\n",
    "    # Environment Parameters\n",
    "    environment_parameters = {\n",
    "        'grid_size': (4, 4),\n",
    "    }\n",
    "\n",
    "    # Hyperparameters\n",
    "    hyperparameters = {\n",
    "        'fem_task_pool_size': 32,\n",
    "        'measurement_pooling_radius': 0.,\n",
    "\n",
    "        'target_update_interval': 100,\n",
    "        'optimization_iter': 10,\n",
    "        'experience_replay_size': 10000,\n",
    "        'replay_batch_size': 32,\n",
    "        'lr': .001,\n",
    "        'discount_factor': .9,\n",
    "        'explore_factor_initial': 1.,\n",
    "        'explore_factor_minimal': 0.05,\n",
    "        'explore_factor_halflife': 2000.,\n",
    "\n",
    "        'final_threshold': 0.01,\n",
    "        'final_step_threshold': 100,\n",
    "\n",
    "        'max_episode': 1000,\n",
    "        'max_step_per_episode': 1000\n",
    "    }    \n",
    "\n",
    "    # exp['Environment_Parameters'] = environment_parameters\n",
    "    # exp['Hyperparameters'] = hyperparameters\n",
    "\n",
    "    return environment_parameters, hyperparameters\n",
    "\n",
    "\n",
    "ep, hp = parameters()\n",
    "\n",
    "ep = SimpleNamespace(**ep)\n",
    "hp = SimpleNamespace(**hp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Reinforcement Learning Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State:\n",
    "    def __init__(self) -> None:\n",
    "        self._dict: Dict[str, Any] = dict()\n",
    "        self.__getitem__ = self._dict.__getitem__\n",
    "        self.__setitem__ = self._dict.__setitem__\n",
    "        self.__delitem__ = self._dict.__delitem__\n",
    "        self.__len__ = self._dict.__len__\n",
    "        \n",
    "    def __getitem__(self, key): return self._dict[key]\n",
    "    \n",
    "    def __setitem__(self, key, value): self._dict[key] = value\n",
    "    \n",
    "    def __len__(self): return len(self._dict)\n",
    "        \n",
    "    def step(self, action: Action) -> State: \n",
    "        return action(copy.deepcopy(self))\n",
    "\n",
    "    def to_tensor(self) -> torch.Tensor: raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "Action = Callable[[State], State]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:    \n",
    "    def __init__(self) -> None:\n",
    "        self._state: State = None\n",
    "        self._action_space: List[Action] = list()\n",
    "        \n",
    "    @property\n",
    "    def state(self) -> State: return self._state\n",
    "    \n",
    "    @property\n",
    "    def action_space(self) -> List[Action]: return self._action_space        \n",
    "\n",
    "    def action_count(self) -> int: return len(self._action_space)        \n",
    "    \n",
    "    def reset(self) -> None: raise NotImplementedError\n",
    "        \n",
    "    def step(self, action_index: int) -> None: raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transition(NamedTuple):\n",
    "    state: State\n",
    "    action_index: int\n",
    "    reward: float\n",
    "    next_state: State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TurnableGridState(State):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self._dict['angle_matrix'] = torch.zeros(ep.grid_size)\n",
    "    \n",
    "    def to_tensor(self) -> torch.Tensor:\n",
    "        return self._dict['angle_matrix'].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TurnableGridEnvironment(Environment):    \n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self._state = TurnableGridState()\n",
    "        \n",
    "        def angle_matrix_action(i, j, modifier):\n",
    "            def action(state):\n",
    "                state['angle_matrix'][i, j] += modifier\n",
    "                return state\n",
    "            return action\n",
    "        \n",
    "        for i in range(ep.grid_size[0]):\n",
    "            for j in range(ep.grid_size[1]):\n",
    "                for modifier in [-15, 15]:\n",
    "                    self._action_space.append(angle_matrix_action(i, j, modifier))\n",
    "\n",
    "    def reset(self) -> None: \n",
    "        self._state = TurnableGridState()\n",
    "        \n",
    "    def step(self, action_index: int) -> None: \n",
    "        action = self._action_space[action_index]\n",
    "        self._state = self._state.step(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Classes\n",
    "\n",
    "class TaskStatus(Enum):\n",
    "    Pending = 0\n",
    "    Running = 1\n",
    "    Successful = 2\n",
    "    Skipped = -1\n",
    "    Failed = -2\n",
    "\n",
    "\n",
    "# A FEMTask instance represent the FEM simulation of a RL transition\n",
    "@dataclass(order=True)\n",
    "class FEMTask():\n",
    "    episode: int = field(compare=False)\n",
    "    step: int\n",
    "    state: State = field(compare=False)\n",
    "    state_key: str = field(compare=False)\n",
    "    action_index: int = field(compare=False)\n",
    "    next_state: State = field(compare=False)\n",
    "    next_state_key: str = field(compare=False)\n",
    "\n",
    "\n",
    "# A FEMSubtask instance represent the FEM simulation of a single state\n",
    "@dataclass()\n",
    "class FEMSubtaskLog():\n",
    "    fem_worker: str = None\n",
    "    queue_time: timedelta = None\n",
    "    mesh_time: Union[str, timedelta] = None\n",
    "    solve_time: Union[str, timedelta] = None\n",
    "    error_msg: str = ''\n",
    "\n",
    "\n",
    "@dataclass(order=True)\n",
    "class FEMSubtask():\n",
    "    episode: int = field(compare=False)\n",
    "    step: int\n",
    "    state: State = field(compare=False)\n",
    "    state_key: str = field(compare=False)\n",
    "    successful: bool = field(default=False, compare=False, init=False)\n",
    "    file_id: str = field(default='', compare=False, init=False)\n",
    "    vtk_path: str = field(default='', compare=False, init=False)\n",
    "    measurement: Tensor = field(default=None, compare=False, init=False, repr=False)\n",
    "    log: FEMSubtaskLog = field(default=FEMSubtaskLog(), compare=False, init=False)\n",
    "\n",
    "\n",
    "@dataclass(order=True)\n",
    "class FEMTaskResult():\n",
    "    episode: int = field(compare=False)\n",
    "    step: int\n",
    "    state: State = field(compare=False)\n",
    "    state_measurement: Tensor = field(compare=False, repr=False)\n",
    "    action_index: int = field(compare=False)\n",
    "    next_state: State = field(compare=False)\n",
    "    next_state_measurement: Tensor = field(compare=False, repr=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridHoleBoardEnv Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridHoleBoardEnv():\n",
    "    def __init__(self,\n",
    "                 size: Tuple[float, float],\n",
    "                 grid_size: Tuple[int, int]) -> None:\n",
    "        self.size: Tuple[float, float] = size\n",
    "        self.grid_size: Tuple[int, int] = grid_size\n",
    "        self.cell_size: Tuple[float, float] = (size[0] / grid_size[0], size[1] / grid_size[1])\n",
    "\n",
    "        self.hole_size_limit: Tuple[float, float] = (0., min(self.cell_size) / 2 - 1)\n",
    "\n",
    "        # (x, y) -> size\n",
    "        self.holes: Tensor = torch.zeros(self.grid_size, device=cuda)\n",
    "\n",
    "        # (x, y) -> (x_coord, y_coord)\n",
    "        self.holes_center: Tensor = torch.zeros((*self.grid_size, 2))\n",
    "\n",
    "        self.action_space: List[Action] = list()\n",
    "        self.action_indices: Dict[Action, int] = dict()\n",
    "\n",
    "        for x in range(self.grid_size[0]):\n",
    "            for y in range(self.grid_size[1]):\n",
    "                self.holes_center[x, y, 0] = (x + 0.5) * self.cell_size[0]\n",
    "                self.holes_center[x, y, 1] = (y + 0.5) * self.cell_size[1]\n",
    "                action = ((x, y), 0.5)\n",
    "                self.action_space.append(action)\n",
    "                self.action_indices[action] = self.action_space.index(action)\n",
    "                action = ((x, y), -0.5)\n",
    "                self.action_space.append(action)\n",
    "                self.action_indices[action] = self.action_space.index(action)\n",
    "\n",
    "        self.valid_action_mask: BoolTensor = torch.tensor([True] * len(self.action_space))\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        self.holes: Tensor = torch.ones(self.grid_size, device=cuda)\n",
    "\n",
    "    def random(self) -> None:\n",
    "        self.holes: Tensor = torch.rand(self.grid_size, device=cuda) * 3\n",
    "\n",
    "    def step(self, action_index: int) -> None:\n",
    "        action = self.action_space[action_index]\n",
    "        (x, y), size_change = action\n",
    "\n",
    "        new_size = self.holes[x, y] + size_change\n",
    "        self.holes[x, y] = torch.clamp(new_size, *self.hole_size_limit)\n",
    "        \n",
    "#         # size-\n",
    "#         if size_change < 0:\n",
    "#             if new_size < self.hole_size_limit[0]:    # size=[0, lower_bound]\n",
    "#                 new_size = 0.    # Jump to size 0\n",
    "#             if new_size <= 0.:\n",
    "#                 self.valid_action_mask[action_index] = False\n",
    "#             # Enable size+ action\n",
    "#             self.valid_action_mask[self.action_indices[(x, y), -size_change]] = True\n",
    "                \n",
    "#         # size+\n",
    "#         elif size_change > 0:\n",
    "#             if new_size >= self.hole_size_limit[1]:    # [upper_bound, +inf)\n",
    "#                 new_size = self.hole_size_limit[1]\n",
    "#                 self.valid_action_mask[action_index] = False\n",
    "#             elif new_size < self.hole_size_limit[0]:   # (0, lower_bound)\n",
    "#                 new_size = self.hole_size_limit[0]    # Jump to lower_bound\n",
    "#             # Enable size- action\n",
    "#             self.valid_action_mask[self.action_indices[(x, y), -size_change]] = True\n",
    "            \n",
    "#         self.holes[x, y] = new_size\n",
    "        \n",
    "        # if self.holes[x, y] < self.hole_size_limit[0]:\n",
    "        #     if size_change <= 0:\n",
    "        #         self.holes[x, y] = 0.\n",
    "        #     else:\n",
    "        #         self.holes[x, y] = self.hole_size_limit[0]\n",
    "        # else:\n",
    "        #     self.holes[x, y] = torch.clamp(self.holes[x, y], *self.hole_size_limit)\n",
    "\n",
    "    def get_state(self) -> State:\n",
    "        return self.holes.clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocess FEM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEMConfig Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridHoleBoardFEMTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FEMWorkerInitializer(mp_result_queue: Queue,\n",
    "                         mp_file_cache: Dict[str, str],\n",
    "                         mp_measurement_cache: Dict[str, Tensor],\n",
    "                         env_board_size: Tuple[float, float],\n",
    "                         env_grid_size: Tuple[int, int],\n",
    "                         env_holes_center: Tensor,\n",
    "                         env_measuring_spots: Tensor,\n",
    "                         env_pooling_radius: float,\n",
    "                         shared_fem_parameters: SimpleNamespace) -> None:\n",
    "    global result_queue, file_cache, measurement_cache\n",
    "    global board_size, grid_size, holes_center\n",
    "    global measuring_spots, pooling_radius, fem_parameters\n",
    "\n",
    "    result_queue = mp_result_queue\n",
    "    file_cache = mp_file_cache\n",
    "    measurement_cache = mp_measurement_cache\n",
    "    board_size = env_board_size\n",
    "    grid_size = env_grid_size\n",
    "    holes_center = env_holes_center\n",
    "    measuring_spots = env_measuring_spots\n",
    "    pooling_radius = env_pooling_radius\n",
    "    fem_parameters = shared_fem_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GridHoleBoardFEMTask(subtask: FEMSubtask, queue_time: datetime) -> None:\n",
    "    import os\n",
    "    import sys\n",
    "    import multiprocess\n",
    "\n",
    "    devnull = open(os.devnull, 'w')\n",
    "    oldstdout_fno = os.dup(sys.stdout.fileno())\n",
    "    os.dup2(devnull.fileno(), 1)\n",
    "\n",
    "    import uuid\n",
    "    from datetime import datetime\n",
    "\n",
    "    import getfem as gf\n",
    "    import numpy as np\n",
    "\n",
    "    import torch\n",
    "\n",
    "    import pyvista as pv\n",
    "    \n",
    "    from scipy.spatial import cKDTree\n",
    "\n",
    "    \n",
    "    # Creating references for shorter notation\n",
    "    state = subtask.state\n",
    "    state_key = subtask.state_key\n",
    "\n",
    "    fp = fem_parameters\n",
    "\n",
    "    # Timer\n",
    "    start_time = datetime.now()\n",
    "    queue_time = datetime.now() - queue_time\n",
    "\n",
    "    fem_worker = multiprocess.current_process().name\n",
    "    \n",
    "    subtask.log.queue_time = queue_time\n",
    "    subtask.log.fem_worker = fem_worker\n",
    "    \n",
    "    failed = False\n",
    "\n",
    "    # Generate Mesh\n",
    "    try:\n",
    "        board = gf.MesherObject('rectangle', [0., 0.], list(board_size))\n",
    "        holes: List[gf.MesherObject] = list()\n",
    "\n",
    "        for x in range(grid_size[0]):\n",
    "            for y in range(grid_size[1]):\n",
    "                center = holes_center[x, y].tolist()\n",
    "                size = state[x, y].item()\n",
    "\n",
    "                if size < 0.01 * fp.element_diameter: continue\n",
    "\n",
    "                holes.append(gf.MesherObject('ball', center, size))\n",
    "\n",
    "        if holes:\n",
    "            holes_union = gf.MesherObject('union', *holes)\n",
    "            mesher = gf.MesherObject('set minus', board, holes_union)\n",
    "        else:\n",
    "            mesher = board\n",
    "\n",
    "        #print('Beginning mesh generation')\n",
    "        gf.util('trace level', 0)   # No trace for mesh generation\n",
    "        mesh = gf.Mesh('generate', mesher, fp.element_diameter, 2, measuring_spots.T)\n",
    "\n",
    "        boundary: Dict[str, int] = dict()\n",
    "\n",
    "        # Boundary of the holes\n",
    "        boundary['HOLE_BOUND'] = 1\n",
    "        mesh.set_region(boundary['HOLE_BOUND'],\n",
    "                        mesh.outer_faces_in_box([1., 1.],\n",
    "                                                [board_size[0] - 1, board_size[1] - 1]))\n",
    "\n",
    "        boundary['LEFT_BOUND'] = 2\n",
    "        mesh.set_region(boundary['LEFT_BOUND'], mesh.outer_faces_with_direction([-1., 0.], 0.01))\n",
    "\n",
    "        boundary['RIGHT_BOUND'] = 3\n",
    "        mesh.set_region(boundary['RIGHT_BOUND'], mesh.outer_faces_with_direction([ 1., 0.], 0.01))\n",
    "\n",
    "        boundary['TOP_BOUND'] = 4\n",
    "        mesh.set_region(boundary['TOP_BOUND'], mesh.outer_faces_with_direction([0.,  1.], 0.01))\n",
    "\n",
    "        boundary['BOTTOM_BOUND'] = 5\n",
    "        mesh.set_region(boundary['BOTTOM_BOUND'], mesh.outer_faces_with_direction([0., -1.], 0.01))\n",
    "\n",
    "        mesh.region_subtract( boundary['RIGHT_BOUND'], boundary['HOLE_BOUND'])\n",
    "        mesh.region_subtract(  boundary['LEFT_BOUND'], boundary['HOLE_BOUND'])\n",
    "        mesh.region_subtract(   boundary['TOP_BOUND'], boundary['HOLE_BOUND'])\n",
    "        mesh.region_subtract(boundary['BOTTOM_BOUND'], boundary['HOLE_BOUND'])\n",
    "\n",
    "        region_id = 7\n",
    "        for x in range(grid_size[0]):\n",
    "            for y in range(grid_size[1]):\n",
    "                center = holes_center[x, y].tolist()\n",
    "                size = state[x, y].item()\n",
    "                bound_key = f'HOLE{x}_{y}_BOUND'\n",
    "                boundary[bound_key] = region_id\n",
    "                mesh.set_region(boundary[bound_key],\n",
    "                                mesh.outer_faces_in_ball(center, size + 0.01 * fp.element_diameter))\n",
    "                if region_id == 7:\n",
    "                    boundary['HOLE_UNION_BOUND'] = 6\n",
    "                    mesh.set_region(boundary['HOLE_UNION_BOUND'],\n",
    "                                mesh.outer_faces_in_ball(center, size + 0.01 * fp.element_diameter))\n",
    "                else:\n",
    "                    mesh.region_merge(boundary['HOLE_UNION_BOUND'], boundary[bound_key])\n",
    "                region_id += 1\n",
    "\n",
    "        np.testing.assert_array_equal(mesh.region(boundary['HOLE_BOUND']),\n",
    "                                      mesh.region(boundary['HOLE_UNION_BOUND']))\n",
    "        \n",
    "        mesh_time = datetime.now() - start_time\n",
    "        subtask.log.mesh_time = mesh_time\n",
    "    except Exception as err:\n",
    "        subtask.log.mesh_time = 'Failed'\n",
    "        subtask.log.solve_time = 'Skipped'\n",
    "        subtask.log.error_msg += str(err) + '\\n'\n",
    "        \n",
    "        failed = True\n",
    "\n",
    "    # Solve\n",
    "    if not failed:\n",
    "        try:\n",
    "\n",
    "\n",
    "            #\n",
    "            # Definition of finite elements methods and integration method\n",
    "            #\n",
    "\n",
    "            mfu = gf.MeshFem(mesh, 2)  # Finite element for the elastic displacement\n",
    "            mfu.set_classical_fem(fp.elements_degree)\n",
    "            mft = gf.MeshFem(mesh, 1)  # Finite element for temperature and electrical field\n",
    "            mft.set_classical_fem(fp.elements_degree)\n",
    "            mfvm = gf.MeshFem(mesh, 1) # Finite element for Von Mises stress interpolation\n",
    "            mfvm.set_classical_discontinuous_fem(fp.elements_degree)\n",
    "            mim = gf.MeshIm(mesh, fp.elements_degree * 2)   # Integration method\n",
    "\n",
    "            md=gf.Model('real');\n",
    "            md.add_fem_variable('u', mfu)       # Displacement of the structure\n",
    "            md.add_fem_variable('theta', mft)   # Temperature\n",
    "            md.add_fem_variable('V', mft)       # Electric potential\n",
    "\n",
    "            # Membrane elastic deformation\n",
    "            md.add_initialized_data('cmu', [fp.cmu])\n",
    "            md.add_initialized_data('clambdastar', [fp.clambdastar])\n",
    "            md.add_isotropic_linearized_elasticity_brick(mim, 'u', 'clambdastar', 'cmu')\n",
    "\n",
    "            md.add_Dirichlet_condition_with_multipliers(mim, 'u', fp.elements_degree - 1, boundary['LEFT_BOUND'])\n",
    "            md.add_initialized_data('Fdata', [fp.F * fp.epsilon, 0])\n",
    "            md.add_source_term_brick(mim, 'u', 'Fdata', boundary['RIGHT_BOUND'])\n",
    "\n",
    "            # Electrical field\n",
    "            sigmaeps = '(eps/(rho_0*(1+alpha*(theta-T0))))'\n",
    "            md.add_initialized_data('eps', [fp.epsilon])\n",
    "            md.add_initialized_data('rho_0', [fp.rho_0])\n",
    "            md.add_initialized_data('alpha', [fp.alpha])\n",
    "            md.add_initialized_data('T0', [fp.T0])\n",
    "            md.add_nonlinear_term(mim, sigmaeps+'*(Grad_V.Grad_Test_V)')\n",
    "            md.add_Dirichlet_condition_with_multipliers(mim, 'V', fp.elements_degree - 1, boundary['RIGHT_BOUND'])\n",
    "            md.add_initialized_data('DdataV', [2.])\n",
    "            md.add_Dirichlet_condition_with_multipliers(mim, 'V', fp.elements_degree - 1, boundary['LEFT_BOUND'], 'DdataV')\n",
    "\n",
    "            # Thermal problem\n",
    "            md.add_initialized_data('kaeps', [fp.kappa * fp.epsilon])\n",
    "            md.add_generic_elliptic_brick(mim, 'theta', 'kaeps')\n",
    "            md.add_initialized_data('D2', [fp.D * 2])\n",
    "            md.add_initialized_data('D2airt', [fp.air_temp * fp.D * 2])\n",
    "            md.add_mass_brick(mim, 'theta', 'D2')\n",
    "            md.add_source_term_brick(mim, 'theta', 'D2airt')\n",
    "            md.add_initialized_data('Deps', [fp.D / fp.epsilon])\n",
    "            md.add_initialized_data('Depsairt', [fp.air_temp * fp.D / fp.epsilon])\n",
    "            md.add_Fourier_Robin_brick(mim, 'theta', 'Deps', boundary['TOP_BOUND'])\n",
    "            md.add_source_term_brick(mim, 'theta', 'Depsairt', boundary['TOP_BOUND'])\n",
    "            md.add_Fourier_Robin_brick(mim, 'theta', 'Deps', boundary['BOTTOM_BOUND'])\n",
    "            md.add_source_term_brick(mim, 'theta', 'Depsairt', boundary['BOTTOM_BOUND'])\n",
    "\n",
    "            # Joule heating term\n",
    "            md.add_nonlinear_term(mim, '-' + sigmaeps + '*Norm_sqr(Grad_V)*Test_theta')\n",
    "\n",
    "            # Thermal expansion term\n",
    "            md.add_initialized_data('beta', [fp.alpha_th * fp.E / (1 - 2 * fp.nu)])\n",
    "            md.add_linear_term(mim, 'beta*(T0-theta)*Trace(Grad_Test_u)')\n",
    "\n",
    "            #\n",
    "            # Model solve\n",
    "            #\n",
    "\n",
    "            md.disable_variable('u')\n",
    "            md.solve('max_res', 1E-9, 'max_iter', 100)\n",
    "\n",
    "            #\n",
    "            # Solution export\n",
    "            #\n",
    "            THETA = md.variable('theta')\n",
    "\n",
    "            file_id = uuid.uuid4()\n",
    "\n",
    "            vtk_path = f'temp/{file_id}.vtk'\n",
    "            mft.export_to_vtk(vtk_path, mft, THETA, 'Temperature')\n",
    "\n",
    "            solve_time = datetime.now() - start_time - mesh_time\n",
    "            subtask.log.solve_time = solve_time\n",
    "        except Exception as err:\n",
    "            subtask.log.solve_time = 'Failed'\n",
    "            subtask.log.error_msg += str(err) + '\\n'\n",
    "\n",
    "            failed = True\n",
    "\n",
    "    if not failed:\n",
    "        subtask.file_id = file_id\n",
    "        subtask.vtk_path = vtk_path\n",
    "        \n",
    "        file_cache[state_key] = vtk_path\n",
    "\n",
    "        m = pv.read(vtk_path)\n",
    "\n",
    "        tree = cKDTree(m.points.astype(np.double))\n",
    "        spots_3d = torch.hstack([measuring_spots, torch.zeros(measuring_spots.size()[0]).unsqueeze(1)])\n",
    "\n",
    "        if pooling_radius == 0.:\n",
    "            _, point_indices = tree.query(spots_3d)\n",
    "            values = np.array(m.active_scalars)[point_indices]\n",
    "        else:\n",
    "            point_pools = tree.query_ball_point(spots_3d, pooling_radius)\n",
    "            values = []\n",
    "            for pool in point_pools:\n",
    "                values.append(np.array(m.active_scalars)[pool].mean())\n",
    "\n",
    "        measurement = torch.tensor(values)\n",
    "        measurement_cache[state_key] = measurement\n",
    "        subtask.measurement = measurement\n",
    "\n",
    "    os.dup2(oldstdout_fno, 1)\n",
    "    devnull.close()\n",
    "\n",
    "    result_queue.put(subtask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RenderTask"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def RenderTask(render_queue: Queue, result_queue: Queue,\n",
    "               measurement_cache: Dict[str, str], result_image_cache: Dict[str, Tensor],\n",
    "               device: torch.device) -> None:\n",
    "    from datetime import datetime\n",
    "    import multiprocess\n",
    "\n",
    "    import numpy as np\n",
    "    from PIL import Image, ImageChops\n",
    "\n",
    "    import torch\n",
    "    from torchvision.transforms import PILToTensor\n",
    "\n",
    "    import pyvista as pv\n",
    "    from pyvirtualdisplay.display import Display\n",
    "    # Render Image\n",
    "    with Display(visible=0, size=(1280, 1024)) as display:\n",
    "        p = pv.Plotter(off_screen=True, lighting='three lights')\n",
    "        p.enable_3_lights()\n",
    "        if p.scalar_bars:\n",
    "            for sb in list(p.scalar_bars.keys()):\n",
    "                p.remove_scalar_bar(sb)\n",
    "\n",
    "        to_tensor = PILToTensor()\n",
    "\n",
    "        render_worker = multiprocess.current_process().name\n",
    "\n",
    "\n",
    "        # Starting Pipeline render_queue => this => result_queue\n",
    "        while True:\n",
    "            err = ''\n",
    "            start_time = datetime.now()\n",
    "            \n",
    "            subtask = render_queue.get()\n",
    "            \n",
    "            vtk_path = subtask.vtk_path\n",
    "            file_id = subtask.file_id\n",
    "            state_key = subtask.state_key\n",
    "\n",
    "            # Skip if FEM task failed in any step\n",
    "            if vtk_path == '' or file_id == '':\n",
    "                subtask.log.render_time = 'Skipped'\n",
    "                result_queue.put(subtask)\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                m = pv.read(vtk_path)\n",
    "\n",
    "                a = p.add_mesh(m, line_width=5, cmap='Greys_r', clim=[20, 60], show_scalar_bar=False)\n",
    "\n",
    "                p.view_xy()\n",
    "\n",
    "                img_path = f'result/{file_id}.png'\n",
    "\n",
    "                img_arr = p.screenshot(filename=None, transparent_background=True, window_size=[512, 384])\n",
    "\n",
    "                p.remove_actor(a, render=False)\n",
    "                # Try whether deep clean is nessary for large dataset\n",
    "                #p.deep_clean()\n",
    "\n",
    "                img = Image.fromarray(img_arr)\n",
    "                bg = Image.new(img.mode, img.size, img.getpixel((0,0)))\n",
    "                diff = ImageChops.difference(img, bg)\n",
    "                diff = ImageChops.add(diff, diff, 2.0, -100)\n",
    "                bbox = diff.getbbox()\n",
    "                if bbox:\n",
    "                    img = img.crop(bbox)\n",
    "                    \n",
    "                img.save(img_path)\n",
    "                \n",
    "                img_tensor = to_tensor(img).to(device=device)\n",
    "                #img_tensor = to_tensor(img).to(device=device, dtype=torch.float)\n",
    "\n",
    "                measurement_cache[state_key] = file_id\n",
    "                result_image_cache[state_key] = img_tensor\n",
    "\n",
    "                render_time = datetime.now() - start_time\n",
    "\n",
    "            except Exception as err:\n",
    "                subtask.log.render_time = 'Failed'\n",
    "\n",
    "                result_queue.put(subtask)\n",
    "\n",
    "            subtask.log.render_time = render_time\n",
    "\n",
    "            subtask.img_path = img_path\n",
    "            subtask.img_tensor = img_tensor\n",
    "\n",
    "            subtask.successful = True\n",
    "            result_queue.put(subtask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridHoleBoardFEMSimulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridHoleBoardFEMSimulator():\n",
    "    def __init__(self,\n",
    "                 environment: GridHoleBoardEnv,\n",
    "                 *,\n",
    "                 fem_task_pool_size: int = hp.fem_task_pool_size,\n",
    "                 measuring_spots: List[List[float]] = ep.measuring_spots,\n",
    "                 pooling_radius: float = hp.measurement_pooling_radius) -> None:\n",
    "        self.environment = environment\n",
    "        self.board_size = environment.size\n",
    "        self.grid_size = environment.grid_size\n",
    "        self.holes_center = environment.holes_center.cpu()\n",
    "        self.measuring_spots = torch.tensor(measuring_spots)\n",
    "        self.pooling_radius = pooling_radius\n",
    "\n",
    "        self.mp_manager: Manager = Manager()\n",
    "\n",
    "        self.mp_result_queue: Queue = self.mp_manager.Queue()\n",
    "\n",
    "        self.mp_file_cache: Dict[str, str] = self.mp_manager.dict()\n",
    "        self.mp_measurement_cache: Dict[str, Tensor] = self.mp_manager.dict()\n",
    "\n",
    "        self.mp_fem_task_pool_size: int = fem_task_pool_size\n",
    "        self.mp_fem_task_pool: Pool = Pool(fem_task_pool_size,\n",
    "                                           initializer=FEMWorkerInitializer,\n",
    "                                           initargs=(self.mp_result_queue,\n",
    "                                                     self.mp_file_cache,\n",
    "                                                     self.mp_measurement_cache,\n",
    "                                                     self.board_size,\n",
    "                                                     self.grid_size,\n",
    "                                                     self.holes_center,\n",
    "                                                     self.measuring_spots,\n",
    "                                                     self.pooling_radius,\n",
    "                                                     fp))\n",
    "\n",
    "        self.task_list: List[FEMTask] = list()\n",
    "        self.subtask_status: Dict[str, TaskStatus] = dict()    # state_key -> task_status\n",
    "\n",
    "        self.cache_stat: Dict[str, int] = {'newly_solved': 0, 'same_episode': 0, 'value_cache': 0, 'file_cache': 0}\n",
    "\n",
    "    def clear_image_cache(self):\n",
    "        self.mp_measurement_cache.clear()\n",
    "\n",
    "    def terminate_current_queue(self):\n",
    "        self.mp_fem_task_pool.terminate()\n",
    "\n",
    "    def reset_task_pool(self):\n",
    "        exp['cache_stat'].log(str(self.cache_stat))\n",
    "        self.cache_stat = {'newly_solved': 0, 'same_episode': 0, 'value_cache': 0, 'file_cache': 0}\n",
    "        exp['cache_stat'].log(str({'subtask_count': len(self.subtask_status), \n",
    "                                   'value_cache_size': len(self.mp_measurement_cache), \n",
    "                                   'file_cache_size': len(self.mp_file_cache)}))\n",
    "        self.task_list.clear()\n",
    "        self.subtask_status.clear()\n",
    "        self.mp_fem_task_pool = Pool(self.mp_fem_task_pool_size,\n",
    "                                     initializer=FEMWorkerInitializer,\n",
    "                                     initargs=(self.mp_result_queue,\n",
    "                                               self.mp_file_cache,\n",
    "                                               self.mp_measurement_cache,\n",
    "                                               self.board_size,\n",
    "                                               self.grid_size,\n",
    "                                               self.holes_center,\n",
    "                                               self.measuring_spots,\n",
    "                                               self.pooling_radius,\n",
    "                                               fp))\n",
    "\n",
    "    def queue_subtask(self, subtask: FEMSubtask) -> None:\n",
    "        state_key = subtask.state_key\n",
    "\n",
    "        if state_key not in self.subtask_status:\n",
    "            # Fallback to image cache\n",
    "            if state_key in self.mp_measurement_cache:\n",
    "                exp['state_cache'].log(f'From ImgCache: {state_key}')\n",
    "                self.cache_stat['value_cache'] += 1\n",
    "                self.subtask_status[state_key] = TaskStatus.Successful\n",
    "            else:\n",
    "                # Fallback to file cache\n",
    "                if state_key in self.mp_file_cache:\n",
    "                    exp['state_cache'].log(f'From FileCache: {state_key}')\n",
    "                    self.cache_stat['file_cache'] += 1\n",
    "                    self.load_from_cache(state_key)\n",
    "                else:\n",
    "                    # Run FEM for unseen state\n",
    "                    exp['state_cache'].log(f'Solve New: {state_key}')\n",
    "                    self.cache_stat['newly_solved'] += 1\n",
    "                    self.subtask_status[state_key] = TaskStatus.Pending\n",
    "                    queue_time = datetime.now()\n",
    "\n",
    "                    def err_callback(err):\n",
    "                        with open('fem_err.log', 'a') as log:\n",
    "                            print('========', file=log)\n",
    "                            print(datetime.now(), file=log)\n",
    "                            print(subtask, file=log)\n",
    "                            print(err, file=log)\n",
    "\n",
    "                    self.mp_fem_task_pool.apply_async(func=GridHoleBoardFEMTask,\n",
    "                                                      args=(subtask, queue_time),\n",
    "                                                      error_callback=err_callback)\n",
    "        else:\n",
    "            exp['state_cache'].log(f'From Same Episode: {state_key}')\n",
    "            self.cache_stat['same_episode'] += 1\n",
    "\n",
    "    def load_from_cache(self, state_key: str):\n",
    "        vtk_path = self.mp_file_cache[state_key]\n",
    "        \n",
    "        m = pv.read(vtk_path)\n",
    "\n",
    "        tree = cKDTree(m.points.astype(np.double))\n",
    "        spots_3d = torch.hstack([self.measuring_spots, torch.zeros(self.measuring_spots.size()[0]).unsqueeze(1)])\n",
    "\n",
    "        if self.pooling_radius == 0.:\n",
    "            _, point_indices = tree.query(spots_3d)\n",
    "            values = np.array(m.active_scalars)[point_indices]\n",
    "        else:\n",
    "            point_pools = tree.query_ball_point(spots_3d, self.pooling_radius)\n",
    "            values = []\n",
    "            for pool in point_pools:\n",
    "                values.append(np.array(m.active_scalars)[pool].mean())\n",
    "                \n",
    "        self.mp_measurement_cache[state_key] = torch.tensor(values)\n",
    "        self.subtask_status[state_key] = TaskStatus.Successful\n",
    "\n",
    "    def queue_transition(self, episode: int, step: int,\n",
    "                         state: State, action_index: int, next_state: State) -> None:\n",
    "\n",
    "        state_key = str(state.flatten().tolist())\n",
    "        next_state_key = str(next_state.flatten().tolist())\n",
    "\n",
    "        self.queue_subtask(FEMSubtask(episode, step, state, state_key))\n",
    "        self.queue_subtask(FEMSubtask(episode, step, next_state, next_state_key))\n",
    "\n",
    "        task = FEMTask(episode, step, state, state_key, action_index, next_state, next_state_key)\n",
    "\n",
    "        self.task_list.append(task)\n",
    "\n",
    "    def get_transition_result(self) -> Generator[FEMTaskResult, None, None]:\n",
    "        for task in self.task_list:\n",
    "            # Retrieve more subtask results if there is pending subtask in current task\n",
    "            while self.subtask_status[task.state_key] is TaskStatus.Pending \\\n",
    "                    or self.subtask_status[task.next_state_key] is TaskStatus.Pending:\n",
    "                self.retrieve_next_task_result()\n",
    "\n",
    "            result = FEMTaskResult(task.episode, task.step,\n",
    "                                   task.state, None,\n",
    "                                   task.action_index,\n",
    "                                   task.next_state, None)\n",
    "\n",
    "            if self.subtask_status[task.state_key] is TaskStatus.Successful:\n",
    "                result.state_measurement = self.mp_measurement_cache[task.state_key]\n",
    "\n",
    "            if self.subtask_status[task.next_state_key] is TaskStatus.Successful:\n",
    "                result.next_state_measurement = self.mp_measurement_cache[task.next_state_key]\n",
    "\n",
    "            yield result\n",
    "\n",
    "    def retrieve_next_task_result(self) -> None:\n",
    "        result: FEMSubtask = fem.mp_result_queue.get(timeout=30)\n",
    "        exp['measurement'].log(result.measurement)\n",
    "        queue_time = 0. if isinstance(result.log.queue_time, str) else result.log.queue_time.total_seconds()\n",
    "        mesh_time = 0. if isinstance(result.log.mesh_time, str) else result.log.mesh_time.total_seconds()\n",
    "        solve_time = 0. if isinstance(result.log.solve_time, str) else result.log.solve_time.total_seconds()\n",
    "        \n",
    "        exp['fem_times/queue_time'].log(queue_time)\n",
    "        exp['fem_times/mesh_time'].log(mesh_time)\n",
    "        exp['fem_times/solve_time'].log(solve_time)\n",
    "\n",
    "        if result.successful:\n",
    "            self.subtask_status[result.state_key] = TaskStatus.Successful\n",
    "        else:\n",
    "            self.subtask_status[result.state_key] = TaskStatus.Failed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEM-based Reward & Final Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FEMReward():\n",
    "    def __init__(self,\n",
    "                 environment: GridHoleBoardEnv,\n",
    "                 target: Tensor,\n",
    "                 max_step: int = hp.max_step_per_episode,\n",
    "                 goal_reward: float = 10000.,\n",
    "                 final_state_error_threshold: float = 1,\n",
    "                 loop_penalty: float = -10000) -> None:\n",
    "        self.environment: GridHoleBoardEnv = environment\n",
    "\n",
    "        self.target_spot = target\n",
    "        exp['target_value'] = target\n",
    "\n",
    "        self.loss = nn.MSELoss(reduction='sum')\n",
    "\n",
    "\n",
    "        self.goal_reward = goal_reward\n",
    "        self.final_state_error_threshold = final_state_error_threshold\n",
    "        self.loop_penalty = loop_penalty\n",
    "\n",
    "\n",
    "    def __call__(self, result: FEMTaskResult) -> Tuple[Optional[float], bool]:\n",
    "        reward = 0.\n",
    "        final = False\n",
    "        \n",
    "        if result.state_measurement is None:\n",
    "            return None, False\n",
    "\n",
    "        error = float(self.loss(result.state_measurement, self.target_spot))\n",
    "        final = error <= self.final_state_error_threshold\n",
    "        \n",
    "        # If the state not changed after apply the action(s_n -> s_n),\n",
    "        # the loop penalty is applied\n",
    "        if torch.equal(result.state, result.next_state):\n",
    "            reward += self.loop_penalty\n",
    "\n",
    "        if result.next_state_measurement is None:\n",
    "            return reward, final\n",
    "\n",
    "        next_error = float(self.loss(result.next_state_measurement, self.target_spot))\n",
    "        \n",
    "        # Reward decreasing error from state to next state\n",
    "        reward += error - next_error\n",
    "        \n",
    "        # Reward extra points if next state is final\n",
    "        if next_error <= self.final_state_error_threshold:\n",
    "            reward += self.goal_reward\n",
    "            \n",
    "        log.step(result.episode, result.step)\n",
    "        log['rewards/reward'] = reward\n",
    "        log['rewards/error'] = error\n",
    "\n",
    "        return reward, final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Network Container\n",
    "class Model():\n",
    "    def __init__(self, network: nn.Module, loss_func: _Loss, optimizer: Optimizer):\n",
    "        self.network = network\n",
    "        self.loss_func = loss_func\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "    def __call__(self, network_input: Tensor) -> Tensor:\n",
    "        return self.network(network_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QNet(state_size: int = 12, action_number: int = 24, target_network: bool = False):\n",
    "    net = nn.Sequential(\n",
    "        nn.Linear(state_size, 100, device=cuda),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(100, 200, device=cuda),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(200, action_number, device=cuda),\n",
    "    )\n",
    "    if target_network:\n",
    "        return Model(network=net, loss_func=None, optimizer=None)\n",
    "    else:\n",
    "        exp['Network'] = str(torchinfo.summary(net, input_size=(32, state_size), \n",
    "                                               device=cuda, verbose=0))\n",
    "        return Model(network=net, loss_func=nn.SmoothL1Loss(), optimizer=torch.optim.Adam(net.parameters(), 0.001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replay Memory Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory():\n",
    "    def __init__(self, capacity):\n",
    "        self.memory: deque = deque([],maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### Agent Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self,\n",
    "                 environment: GridHoleBoardEnv,\n",
    "                 fem_simulator: GridHoleBoardFEMSimulator,\n",
    "                 fem_reward_func: Callable[[Tensor, int, Tensor], float],\n",
    "                 q_network: nn.Module,\n",
    "                 target_network: nn.Module,\n",
    "                 target_update_interval: int = hp.target_update_interval,\n",
    "                 optimization_iter: int = hp.optimization_iter,\n",
    "                 max_step_per_episode: int = hp.max_step_per_episode,\n",
    "                 experience_replay: ReplayMemory = ReplayMemory(hp.experience_replay_size),\n",
    "                 replay_batch_size: int = hp.replay_batch_size,\n",
    "                 discount_factor: float = hp.discount_factor,\n",
    "                 explore_factor_initial: float = hp.explore_factor_initial,\n",
    "                 explore_factor_minimal: float = hp.explore_factor_minimal,\n",
    "                 explore_factor_halflife: float = hp.explore_factor_halflife,\n",
    "                ) -> None:\n",
    "        self.environment: GridHoleBoardEnv = environment\n",
    "        self.fem_simulator: GridHoleBoardFEMSimulator = fem_simulator\n",
    "        self.fem_reward_func: Callable[[Tensor, int, Tensor], float] = fem_reward_func\n",
    "\n",
    "        self.q_network: Model = q_network\n",
    "        self.target_network: Model = target_network\n",
    "        self.target_update_interval: int = target_update_interval\n",
    "\n",
    "        self.optimization_iter: int = optimization_iter\n",
    "        self.max_step_per_episode: int = max_step_per_episode\n",
    "        self.experience_replay: ReplayMemory = experience_replay\n",
    "        self.replay_batch_size: int = replay_batch_size\n",
    "\n",
    "        self.discount_factor: float = discount_factor\n",
    "        self.explore_factor_initial: float = explore_factor_initial\n",
    "        self.explore_factor_minimal: float = explore_factor_minimal\n",
    "        self.explore_factor_halflife: float = explore_factor_halflife\n",
    "        self.explored_step: int = 0\n",
    "\n",
    "\n",
    "    def select_action(self, disable_explore: bool = False) -> Tuple[State, int]:\n",
    "        state = self.environment.get_state()\n",
    "        explore_factor = max(self.explore_factor_initial \n",
    "                             * (0.5 ** (self.explored_step / self.explore_factor_halflife)), \n",
    "                             self.explore_factor_minimal)\n",
    "        exp['explore_factor'].log(explore_factor, step=self.explored_step)\n",
    "        \n",
    "        if random.random() > explore_factor or disable_explore:\n",
    "            prediction = self.q_network(state.flatten())\n",
    "            \n",
    "            \n",
    "            action_index = prediction.flatten().masked_fill(self.environment.valid_action_mask, -1000000.).argmax().item()\n",
    "            exp['actions'].log(f'Action {action_index}')\n",
    "            exp['actions'].log(prediction.flatten())\n",
    "            exp['actions'].log(self.environment.valid_action_mask)\n",
    "            exp['actions'].log(prediction.flatten().masked_fill(self.environment.valid_action_mask, -1000000.))\n",
    "            \n",
    "            # action_index = prediction.argmax().item()\n",
    "            action_type = 'Pred'\n",
    "        else:\n",
    "            action_index = random.randrange(len(self.environment.action_space))\n",
    "            action_type = 'Rand'\n",
    "        self.explored_step += 1\n",
    "        return state, action_index, action_type\n",
    "\n",
    "    def step(self, episode: int, step: int, disable_explore: bool = False) -> bool:\n",
    "        state, action_index, action_type = self.select_action(disable_explore)\n",
    "        \n",
    "        # exp['actions'].log(str(self.environment.valid_action_mask).replace('rue', '').replace('alse', ''))\n",
    "        if action_type == 'Pred':\n",
    "            exp['actions'].log(self.environment.valid_action_mask[action_index])\n",
    "\n",
    "        self.environment.step(action_index)\n",
    "        next_state = self.environment.get_state()\n",
    "        \n",
    "        action = self.environment.action_space[action_index]\n",
    "        action_log = f'{self.explored_step} {action_type} {action} ({state[action[0]]} => {next_state[action[0]]})'\n",
    "        exp['actions'].log(action_log)\n",
    "        \n",
    "        self.fem_simulator.queue_transition(episode, step, state, action_index, next_state)\n",
    "\n",
    "        # Return True if the next state is final\n",
    "        return step >= self.max_step_per_episode\n",
    "\n",
    "    def complete_fem_rewarding(self, episode: int) -> None:\n",
    "        fem = self.fem_simulator    # Create local reference to shorter statements\n",
    "        print('Start computing rewards based on completed FEM simulation')\n",
    "        i = 0\n",
    "        \n",
    "        for result in fem.get_transition_result():\n",
    "            reward, final = self.fem_reward_func(result)\n",
    "            if reward is None:\n",
    "                continue\n",
    "\n",
    "            if final:\n",
    "                next_state = None\n",
    "            else:\n",
    "                next_state = result.next_state\n",
    "\n",
    "            self.experience_replay.push(result.state, result.action_index, reward, next_state)\n",
    "            \n",
    "            i += 1\n",
    "            if i % 100:\n",
    "                print(f'{i}/{self.max_step_per_episode}', end='\\r')\n",
    "            \n",
    "            if final:\n",
    "                fem.terminate_current_queue()\n",
    "                print('Early stop triggered')\n",
    "                return\n",
    "\n",
    "\n",
    "    def optimize(self) -> None:\n",
    "        if len(self.experience_replay) < self.replay_batch_size: return\n",
    "\n",
    "        samples = self.experience_replay.sample(self.replay_batch_size)\n",
    "        batch = Transition(*zip(*samples))\n",
    "\n",
    "        non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                                  batch.next_state)), device=cuda, dtype=torch.bool)\n",
    "        non_final_next_states = torch.stack([s.flatten() for s in batch.next_state\n",
    "                                                        if s is not None])\n",
    "\n",
    "        state_batch = torch.stack([s.flatten() for s in batch.state])\n",
    "        action_batch = torch.tensor(batch.action_index, device=cuda).unsqueeze(1)\n",
    "        reward_batch = torch.tensor(batch.reward, device=cuda)\n",
    "\n",
    "        state_action_values = self.q_network(state_batch).gather(1, action_batch)\n",
    "\n",
    "\n",
    "        next_state_values = torch.zeros(self.replay_batch_size, device=cuda)\n",
    "        next_state_values[non_final_mask] = self.target_network(non_final_next_states).max(1)[0].detach()\n",
    "\n",
    "        expected_state_action_values = (next_state_values * self.discount_factor) + reward_batch\n",
    "\n",
    "        loss = self.q_network.loss_func(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "        exp['optimization_loss'].log(float(loss))\n",
    "        self.q_network.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        for param in self.q_network.network.parameters():\n",
    "            param.grad.data.clamp_(-1, 1)\n",
    "        self.q_network.optimizer.step()\n",
    "\n",
    "    def update_target_network(self) -> None:\n",
    "        self.target_network.network.load_state_dict(self.q_network.network.state_dict())\n",
    "\n",
    "    def train(self, episode: int = hp.max_episode) -> None:\n",
    "        for e in range(episode):\n",
    "            print(f'Episode {e}')\n",
    "            start_time = datetime.now()\n",
    "            self.environment.reset()\n",
    "            # Use fixed number of steps in each episode\n",
    "            for step_num in range(self.max_step_per_episode):\n",
    "                self.step(e, step_num)\n",
    "            self.complete_fem_rewarding(e)\n",
    "            for i in range(self.optimization_iter):\n",
    "                self.optimize()\n",
    "            self.fem_simulator.reset_task_pool()\n",
    "            self.fem_simulator.clear_image_cache()\n",
    "            if e % self.target_update_interval == 0:\n",
    "                # print('Target network update                 ')\n",
    "                self.update_target_network()\n",
    "\n",
    "            end_time = datetime.now()\n",
    "            print(f'Episode {e} completed in {end_time - start_time}')\n",
    "\n",
    "    def generate(self, step: int = 100) -> State:\n",
    "        pass\n",
    "        # TODO: rewrite\n",
    "        # self.environment.reset()\n",
    "        # for i in range(step):\n",
    "        #     if self.step(100000000, i):\n",
    "        #         print(f'Completed in {step} steps                    ', end='\\r\\n')\n",
    "        #         break\n",
    "        # return self.environment.get_state(), i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = GridHoleBoardEnv(size=ep.size, grid_size=ep.grid_size)\n",
    "\n",
    "fem = GridHoleBoardFEMSimulator(env, measuring_spots=ep.measuring_spots, \n",
    "                                pooling_radius=hp.measurement_pooling_radius)\n",
    "\n",
    "reward_func = FEMReward(env, torch.tensor([30., 30., 30., 30., 30., 30., 30., 30.]))\n",
    "\n",
    "agent = Agent(env, fem, reward_func, QNet(), QNet(target_network=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 0 completed in 0:04:49.626524\n",
      "Episode 1\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 1 completed in 0:03:47.057468\n",
      "Episode 2\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 2 completed in 0:04:11.333822\n",
      "Episode 3\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 3 completed in 0:03:16.926786\n",
      "Episode 4\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 4 completed in 0:02:00.740221\n",
      "Episode 5\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 5 completed in 0:01:43.419541\n",
      "Episode 6\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 6 completed in 0:01:07.019182\n",
      "Episode 7\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 7 completed in 0:01:18.984613\n",
      "Episode 8\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 8 completed in 0:00:39.376069\n",
      "Episode 9\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 9 completed in 0:00:48.374033\n",
      "Episode 10\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 10 completed in 0:00:36.804598\n",
      "Episode 11\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 11 completed in 0:00:55.715390\n",
      "Episode 12\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 12 completed in 0:00:53.956143\n",
      "Episode 13\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 13 completed in 0:01:00.392486\n",
      "Episode 14\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 14 completed in 0:00:50.689838\n",
      "Episode 15\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 15 completed in 0:00:46.456308\n",
      "Episode 16\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 16 completed in 0:00:55.759340\n",
      "Episode 17\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 17 completed in 0:00:38.688644\n",
      "Episode 18\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 18 completed in 0:01:16.489640\n",
      "Episode 19\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 19 completed in 0:00:51.396641\n",
      "Episode 20\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 20 completed in 0:01:03.623472\n",
      "Episode 21\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 21 completed in 0:00:51.736419\n",
      "Episode 22\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 22 completed in 0:00:33.413519\n",
      "Episode 23\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 23 completed in 0:00:47.408253\n",
      "Episode 24\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 24 completed in 0:01:02.875655\n",
      "Episode 25\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 25 completed in 0:00:58.318348\n",
      "Episode 26\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 26 completed in 0:01:02.854157\n",
      "Episode 27\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 27 completed in 0:00:49.788697\n",
      "Episode 28\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 28 completed in 0:00:46.460569\n",
      "Episode 29\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 29 completed in 0:00:52.024453\n",
      "Episode 30\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 30 completed in 0:00:49.387824\n",
      "Episode 31\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 31 completed in 0:00:48.710806\n",
      "Episode 32\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 32 completed in 0:01:02.155674\n",
      "Episode 33\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 33 completed in 0:00:54.295954\n",
      "Episode 34\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 34 completed in 0:00:58.198064\n",
      "Episode 35\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 35 completed in 0:00:42.566048\n",
      "Episode 36\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 36 completed in 0:00:45.089112\n",
      "Episode 37\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 37 completed in 0:00:50.082869\n",
      "Episode 38\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 38 completed in 0:00:54.239240\n",
      "Episode 39\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 39 completed in 0:00:50.944598\n",
      "Episode 40\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 40 completed in 0:00:38.681629\n",
      "Episode 41\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 41 completed in 0:00:59.138243\n",
      "Episode 42\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 42 completed in 0:00:54.450971\n",
      "Episode 43\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 43 completed in 0:00:40.261891\n",
      "Episode 44\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 44 completed in 0:00:46.662292\n",
      "Episode 45\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 45 completed in 0:00:46.633504\n",
      "Episode 46\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 46 completed in 0:00:45.918916\n",
      "Episode 47\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 47 completed in 0:00:46.317609\n",
      "Episode 48\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 48 completed in 0:01:03.272231\n",
      "Episode 49\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 49 completed in 0:01:03.529042\n",
      "Episode 50\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 50 completed in 0:00:30.761550\n",
      "Episode 51\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 51 completed in 0:00:35.527361\n",
      "Episode 52\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 52 completed in 0:00:44.228263\n",
      "Episode 53\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 53 completed in 0:00:42.170178\n",
      "Episode 54\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 54 completed in 0:00:56.128347\n",
      "Episode 55\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 55 completed in 0:00:54.748321\n",
      "Episode 56\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 56 completed in 0:00:35.534591\n",
      "Episode 57\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 57 completed in 0:00:44.741561\n",
      "Episode 58\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 58 completed in 0:01:04.070751\n",
      "Episode 59\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 59 completed in 0:00:34.639713\n",
      "Episode 60\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 60 completed in 0:00:37.667045\n",
      "Episode 61\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 61 completed in 0:00:39.268795\n",
      "Episode 62\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 62 completed in 0:00:57.191811\n",
      "Episode 63\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 63 completed in 0:00:26.330126\n",
      "Episode 64\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 64 completed in 0:00:47.806692\n",
      "Episode 65\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 65 completed in 0:00:46.622418\n",
      "Episode 66\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 66 completed in 0:00:48.499523\n",
      "Episode 67\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 67 completed in 0:00:50.652123\n",
      "Episode 68\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 68 completed in 0:00:45.097904\n",
      "Episode 69\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 69 completed in 0:00:47.559002\n",
      "Episode 70\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 70 completed in 0:00:42.293270\n",
      "Episode 71\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 71 completed in 0:00:52.915308\n",
      "Episode 72\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 72 completed in 0:00:47.225223\n",
      "Episode 73\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 73 completed in 0:00:50.916807\n",
      "Episode 74\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 74 completed in 0:00:54.326247\n",
      "Episode 75\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 75 completed in 0:01:01.676376\n",
      "Episode 76\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 76 completed in 0:00:30.880528\n",
      "Episode 77\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 77 completed in 0:00:33.508230\n",
      "Episode 78\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 78 completed in 0:00:43.965259\n",
      "Episode 79\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 79 completed in 0:00:47.768702\n",
      "Episode 80\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 80 completed in 0:01:00.918886\n",
      "Episode 81\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 81 completed in 0:00:37.502931\n",
      "Episode 82\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 82 completed in 0:00:56.947134\n",
      "Episode 83\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 83 completed in 0:00:50.945779\n",
      "Episode 84\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 84 completed in 0:00:57.787277\n",
      "Episode 85\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 85 completed in 0:00:34.414846\n",
      "Episode 86\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 86 completed in 0:01:06.222449\n",
      "Episode 87\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 87 completed in 0:00:39.909942\n",
      "Episode 88\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 88 completed in 0:00:48.722941\n",
      "Episode 89\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 89 completed in 0:00:45.608753\n",
      "Episode 90\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 90 completed in 0:00:35.855587\n",
      "Episode 91\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 91 completed in 0:01:03.361514\n",
      "Episode 92\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 92 completed in 0:00:33.373529\n",
      "Episode 93\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 93 completed in 0:00:35.481999\n",
      "Episode 94\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 94 completed in 0:00:39.589310\n",
      "Episode 95\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 95 completed in 0:00:44.739864\n",
      "Episode 96\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 96 completed in 0:00:29.791468\n",
      "Episode 97\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 97 completed in 0:00:39.472966\n",
      "Episode 98\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 98 completed in 0:00:49.020348\n",
      "Episode 99\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 99 completed in 0:00:46.704938\n",
      "Episode 100\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 100 completed in 0:00:53.060179\n",
      "Episode 101\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 101 completed in 0:00:37.515822\n",
      "Episode 102\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 102 completed in 0:00:43.387832\n",
      "Episode 103\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 103 completed in 0:00:57.380355\n",
      "Episode 104\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 104 completed in 0:01:02.407532\n",
      "Episode 105\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 105 completed in 0:00:55.540849\n",
      "Episode 106\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 106 completed in 0:00:31.867332\n",
      "Episode 107\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 107 completed in 0:00:52.818973\n",
      "Episode 108\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 108 completed in 0:00:52.441342\n",
      "Episode 109\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 109 completed in 0:00:46.828081\n",
      "Episode 110\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 110 completed in 0:00:44.959913\n",
      "Episode 111\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 111 completed in 0:00:29.013710\n",
      "Episode 112\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 112 completed in 0:00:39.721925\n",
      "Episode 113\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 113 completed in 0:00:36.484791\n",
      "Episode 114\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 114 completed in 0:00:47.810004\n",
      "Episode 115\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 115 completed in 0:00:30.614969\n",
      "Episode 116\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 116 completed in 0:00:31.303861\n",
      "Episode 117\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 117 completed in 0:00:43.321457\n",
      "Episode 118\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 118 completed in 0:00:57.367369\n",
      "Episode 119\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 119 completed in 0:01:00.709716\n",
      "Episode 120\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 120 completed in 0:00:35.094189\n",
      "Episode 121\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 121 completed in 0:00:49.380903\n",
      "Episode 122\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 122 completed in 0:00:44.295579\n",
      "Episode 123\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 123 completed in 0:00:51.676019\n",
      "Episode 124\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 124 completed in 0:01:07.417648\n",
      "Episode 125\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 125 completed in 0:00:33.035251\n",
      "Episode 126\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 126 completed in 0:00:25.479172\n",
      "Episode 127\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 127 completed in 0:00:27.620470\n",
      "Episode 128\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 128 completed in 0:00:59.144503\n",
      "Episode 129\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 129 completed in 0:00:40.687467\n",
      "Episode 130\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 130 completed in 0:00:37.748606\n",
      "Episode 131\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 131 completed in 0:00:45.342631\n",
      "Episode 132\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 132 completed in 0:00:52.019399\n",
      "Episode 133\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 133 completed in 0:00:48.380125\n",
      "Episode 134\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 134 completed in 0:00:41.001786\n",
      "Episode 135\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 135 completed in 0:00:48.396541\n",
      "Episode 136\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 136 completed in 0:00:52.459143\n",
      "Episode 137\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 137 completed in 0:00:52.759830\n",
      "Episode 138\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 138 completed in 0:00:28.048565\n",
      "Episode 139\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 139 completed in 0:00:36.573431\n",
      "Episode 140\n",
      "Start computing rewards based on completed FEM simulation\n",
      "68/1000\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Level 1 Warning in getfem_superlu.cc, line 217: SuperLU solve failed: info =10427\n",
      "Level 1 Warning in getfem_superlu.cc, line 217: SuperLU solve failed: info =10427\n",
      "Level 1 Warning in getfem_superlu.cc, line 217: SuperLU solve failed: info =10427\n",
      "Level 1 Warning in getfem_superlu.cc, line 217: SuperLU solve failed: info =10427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 140 completed in 0:00:49.976751\n",
      "Episode 141\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 141 completed in 0:00:57.193732\n",
      "Episode 142\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 142 completed in 0:01:09.235314\n",
      "Episode 143\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 143 completed in 0:00:43.082637\n",
      "Episode 144\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 144 completed in 0:00:56.241977\n",
      "Episode 145\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 145 completed in 0:00:41.646944\n",
      "Episode 146\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 146 completed in 0:00:50.599988\n",
      "Episode 147\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 147 completed in 0:00:56.950024\n",
      "Episode 148\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 148 completed in 0:00:53.302917\n",
      "Episode 149\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 149 completed in 0:00:46.742528\n",
      "Episode 150\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 150 completed in 0:00:45.113144\n",
      "Episode 151\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 151 completed in 0:00:37.974013\n",
      "Episode 152\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 152 completed in 0:00:36.094788\n",
      "Episode 153\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 153 completed in 0:00:49.318890\n",
      "Episode 154\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 154 completed in 0:00:42.377150\n",
      "Episode 155\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 155 completed in 0:00:38.042724\n",
      "Episode 156\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 156 completed in 0:00:36.254367\n",
      "Episode 157\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 157 completed in 0:00:43.214421\n",
      "Episode 158\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 158 completed in 0:00:52.842798\n",
      "Episode 159\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 159 completed in 0:01:04.299462\n",
      "Episode 160\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 160 completed in 0:00:50.578745\n",
      "Episode 161\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 161 completed in 0:00:58.344805\n",
      "Episode 162\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 162 completed in 0:00:52.137859\n",
      "Episode 163\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 163 completed in 0:00:56.883847\n",
      "Episode 164\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 164 completed in 0:00:39.018674\n",
      "Episode 165\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 165 completed in 0:01:01.389217\n",
      "Episode 166\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 166 completed in 0:00:52.719167\n",
      "Episode 167\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 167 completed in 0:00:39.760444\n",
      "Episode 168\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 168 completed in 0:00:46.096111\n",
      "Episode 169\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 169 completed in 0:00:58.410563\n",
      "Episode 170\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 170 completed in 0:00:42.936828\n",
      "Episode 171\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 171 completed in 0:00:26.058551\n",
      "Episode 172\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 172 completed in 0:00:37.105600\n",
      "Episode 173\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 173 completed in 0:00:56.074591\n",
      "Episode 174\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 174 completed in 0:00:57.820699\n",
      "Episode 175\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 175 completed in 0:00:55.865220\n",
      "Episode 176\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 176 completed in 0:01:02.596245\n",
      "Episode 177\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 177 completed in 0:01:00.174091\n",
      "Episode 178\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 178 completed in 0:00:47.830497\n",
      "Episode 179\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 179 completed in 0:00:38.593292\n",
      "Episode 180\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 180 completed in 0:00:51.456025\n",
      "Episode 181\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 181 completed in 0:00:36.987237\n",
      "Episode 182\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 182 completed in 0:00:55.361071\n",
      "Episode 183\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 183 completed in 0:00:49.076802\n",
      "Episode 184\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 184 completed in 0:00:51.905007\n",
      "Episode 185\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 185 completed in 0:00:50.729901\n",
      "Episode 186\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 186 completed in 0:00:32.886864\n",
      "Episode 187\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 187 completed in 0:00:50.763065\n",
      "Episode 188\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 188 completed in 0:00:39.362599\n",
      "Episode 189\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 189 completed in 0:01:03.342048\n",
      "Episode 190\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 190 completed in 0:00:49.570264\n",
      "Episode 191\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 191 completed in 0:01:00.617116\n",
      "Episode 192\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 192 completed in 0:00:38.562861\n",
      "Episode 193\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 193 completed in 0:01:04.647919\n",
      "Episode 194\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 194 completed in 0:00:42.483424\n",
      "Episode 195\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 195 completed in 0:01:00.457536\n",
      "Episode 196\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 196 completed in 0:00:53.067473\n",
      "Episode 197\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 197 completed in 0:00:40.934333\n",
      "Episode 198\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 198 completed in 0:00:58.085932\n",
      "Episode 199\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 199 completed in 0:00:59.340142\n",
      "Episode 200\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 200 completed in 0:00:51.463406\n",
      "Episode 201\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 201 completed in 0:00:56.201611\n",
      "Episode 202\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 202 completed in 0:00:57.681794\n",
      "Episode 203\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 203 completed in 0:00:34.967712\n",
      "Episode 204\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 204 completed in 0:00:42.762869\n",
      "Episode 205\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 205 completed in 0:00:40.053487\n",
      "Episode 206\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 206 completed in 0:00:49.994944\n",
      "Episode 207\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 207 completed in 0:00:36.900921\n",
      "Episode 208\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 208 completed in 0:00:51.685586\n",
      "Episode 209\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 209 completed in 0:00:59.247930\n",
      "Episode 210\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 210 completed in 0:00:44.886151\n",
      "Episode 211\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 211 completed in 0:00:52.382997\n",
      "Episode 212\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 212 completed in 0:00:45.739600\n",
      "Episode 213\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 213 completed in 0:00:48.941634\n",
      "Episode 214\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 214 completed in 0:00:44.669015\n",
      "Episode 215\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 215 completed in 0:00:33.314559\n",
      "Episode 216\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 216 completed in 0:01:01.877374\n",
      "Episode 217\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 217 completed in 0:01:10.007553\n",
      "Episode 218\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 218 completed in 0:00:29.213022\n",
      "Episode 219\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 219 completed in 0:01:02.126001\n",
      "Episode 220\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 220 completed in 0:00:52.216937\n",
      "Episode 221\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 221 completed in 0:00:43.434761\n",
      "Episode 222\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 222 completed in 0:00:53.095107\n",
      "Episode 223\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 223 completed in 0:00:49.584305\n",
      "Episode 224\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 224 completed in 0:01:06.776699\n",
      "Episode 225\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 225 completed in 0:00:44.349202\n",
      "Episode 226\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 226 completed in 0:00:59.714336\n",
      "Episode 227\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 227 completed in 0:01:01.624464\n",
      "Episode 228\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 228 completed in 0:00:48.992867\n",
      "Episode 229\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 229 completed in 0:00:38.814391\n",
      "Episode 230\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 230 completed in 0:00:31.998888\n",
      "Episode 231\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 231 completed in 0:00:31.581862\n",
      "Episode 232\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 232 completed in 0:01:08.119960\n",
      "Episode 233\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 233 completed in 0:00:49.605730\n",
      "Episode 234\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 234 completed in 0:00:58.768725\n",
      "Episode 235\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 235 completed in 0:00:48.034057\n",
      "Episode 236\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 236 completed in 0:00:34.360900\n",
      "Episode 237\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 237 completed in 0:00:37.503925\n",
      "Episode 238\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 238 completed in 0:00:56.065545\n",
      "Episode 239\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 239 completed in 0:01:15.685984\n",
      "Episode 240\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 240 completed in 0:00:39.968070\n",
      "Episode 241\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 241 completed in 0:01:07.395423\n",
      "Episode 242\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 242 completed in 0:00:39.235237\n",
      "Episode 243\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 243 completed in 0:00:57.441557\n",
      "Episode 244\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 244 completed in 0:00:39.564678\n",
      "Episode 245\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 245 completed in 0:00:54.504273\n",
      "Episode 246\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 246 completed in 0:00:58.996941\n",
      "Episode 247\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 247 completed in 0:00:48.946795\n",
      "Episode 248\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 248 completed in 0:00:28.695884\n",
      "Episode 249\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 249 completed in 0:01:02.144398\n",
      "Episode 250\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 250 completed in 0:00:56.548845\n",
      "Episode 251\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 251 completed in 0:00:43.613494\n",
      "Episode 252\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 252 completed in 0:00:47.155949\n",
      "Episode 253\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 253 completed in 0:00:37.327580\n",
      "Episode 254\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 254 completed in 0:00:41.162926\n",
      "Episode 255\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 255 completed in 0:00:42.366698\n",
      "Episode 256\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 256 completed in 0:00:42.019096\n",
      "Episode 257\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 257 completed in 0:00:39.996643\n",
      "Episode 258\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 258 completed in 0:00:55.576552\n",
      "Episode 259\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 259 completed in 0:00:36.209366\n",
      "Episode 260\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 260 completed in 0:00:44.819545\n",
      "Episode 261\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 261 completed in 0:01:06.305361\n",
      "Episode 262\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 262 completed in 0:00:47.219793\n",
      "Episode 263\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 263 completed in 0:00:47.304900\n",
      "Episode 264\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 264 completed in 0:00:57.705017\n",
      "Episode 265\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 265 completed in 0:01:15.140501\n",
      "Episode 266\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 266 completed in 0:01:01.895893\n",
      "Episode 267\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 267 completed in 0:00:43.514863\n",
      "Episode 268\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 268 completed in 0:01:03.292026\n",
      "Episode 269\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 269 completed in 0:00:29.353125\n",
      "Episode 270\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 270 completed in 0:01:04.543810\n",
      "Episode 271\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 271 completed in 0:00:54.358847\n",
      "Episode 272\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 272 completed in 0:00:39.271526\n",
      "Episode 273\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 273 completed in 0:00:46.574349\n",
      "Episode 274\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 274 completed in 0:00:58.203411\n",
      "Episode 275\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 275 completed in 0:00:41.436562\n",
      "Episode 276\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 276 completed in 0:01:13.216114\n",
      "Episode 277\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 277 completed in 0:00:32.113696\n",
      "Episode 278\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 278 completed in 0:00:52.790791\n",
      "Episode 279\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 279 completed in 0:00:52.506320\n",
      "Episode 280\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 280 completed in 0:00:37.151337\n",
      "Episode 281\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 281 completed in 0:01:08.653930\n",
      "Episode 282\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 282 completed in 0:00:56.152227\n",
      "Episode 283\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 283 completed in 0:00:31.909118\n",
      "Episode 284\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 284 completed in 0:00:32.191878\n",
      "Episode 285\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 285 completed in 0:00:39.473194\n",
      "Episode 286\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 286 completed in 0:00:49.692346\n",
      "Episode 287\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 287 completed in 0:00:41.946542\n",
      "Episode 288\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 288 completed in 0:00:34.665430\n",
      "Episode 289\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 289 completed in 0:00:31.799304\n",
      "Episode 290\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 290 completed in 0:00:48.008908\n",
      "Episode 291\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 291 completed in 0:00:49.733618\n",
      "Episode 292\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 292 completed in 0:00:46.536722\n",
      "Episode 293\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 293 completed in 0:00:41.224739\n",
      "Episode 294\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 294 completed in 0:00:35.851741\n",
      "Episode 295\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 295 completed in 0:00:40.612466\n",
      "Episode 296\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 296 completed in 0:00:30.192943\n",
      "Episode 297\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 297 completed in 0:00:46.305199\n",
      "Episode 298\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 298 completed in 0:00:36.623572\n",
      "Episode 299\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 299 completed in 0:00:43.138139\n",
      "Episode 300\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 300 completed in 0:01:03.373581\n",
      "Episode 301\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 301 completed in 0:00:53.127693\n",
      "Episode 302\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 302 completed in 0:00:34.995829\n",
      "Episode 303\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 303 completed in 0:00:44.195027\n",
      "Episode 304\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 304 completed in 0:00:35.321049\n",
      "Episode 305\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 305 completed in 0:00:44.297126\n",
      "Episode 306\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 306 completed in 0:00:49.049888\n",
      "Episode 307\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 307 completed in 0:00:38.139135\n",
      "Episode 308\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 308 completed in 0:00:45.574747\n",
      "Episode 309\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 309 completed in 0:01:00.663838\n",
      "Episode 310\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 310 completed in 0:00:36.058819\n",
      "Episode 311\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 311 completed in 0:00:33.809392\n",
      "Episode 312\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 312 completed in 0:00:55.998374\n",
      "Episode 313\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 313 completed in 0:01:14.480708\n",
      "Episode 314\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 314 completed in 0:00:37.812567\n",
      "Episode 315\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 315 completed in 0:01:07.326451\n",
      "Episode 316\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 316 completed in 0:00:30.106061\n",
      "Episode 317\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 317 completed in 0:00:32.544554\n",
      "Episode 318\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 318 completed in 0:00:38.270864\n",
      "Episode 319\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 319 completed in 0:00:53.256651\n",
      "Episode 320\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 320 completed in 0:00:57.221782\n",
      "Episode 321\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 321 completed in 0:00:58.759596\n",
      "Episode 322\n",
      "Start computing rewards based on completed FEM simulation\n",
      "19/1000\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Level 1 Warning in getfem_superlu.cc, line 217: SuperLU solve failed: info =10419\n",
      "Level 1 Warning in getfem_superlu.cc, line 217: SuperLU solve failed: info =10419\n",
      "Level 1 Warning in getfem_superlu.cc, line 217: SuperLU solve failed: info =10419\n",
      "Level 1 Warning in getfem_superlu.cc, line 217: SuperLU solve failed: info =10419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 322 completed in 0:01:06.560471\n",
      "Episode 323\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 323 completed in 0:00:32.085999\n",
      "Episode 324\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 324 completed in 0:00:46.746361\n",
      "Episode 325\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 325 completed in 0:01:03.271094\n",
      "Episode 326\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 326 completed in 0:00:49.704407\n",
      "Episode 327\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 327 completed in 0:00:42.141635\n",
      "Episode 328\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 328 completed in 0:00:38.973609\n",
      "Episode 329\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 329 completed in 0:00:46.857976\n",
      "Episode 330\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 330 completed in 0:00:48.317233\n",
      "Episode 331\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 331 completed in 0:00:28.132899\n",
      "Episode 332\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 332 completed in 0:00:46.130087\n",
      "Episode 333\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 333 completed in 0:00:58.131550\n",
      "Episode 334\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 334 completed in 0:01:01.899050\n",
      "Episode 335\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 335 completed in 0:00:42.411801\n",
      "Episode 336\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 336 completed in 0:00:54.395450\n",
      "Episode 337\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 337 completed in 0:00:53.989321\n",
      "Episode 338\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 338 completed in 0:00:31.353240\n",
      "Episode 339\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 339 completed in 0:00:34.564688\n",
      "Episode 340\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 340 completed in 0:00:53.304291\n",
      "Episode 341\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 341 completed in 0:00:41.034817\n",
      "Episode 342\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 342 completed in 0:00:43.315414\n",
      "Episode 343\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 343 completed in 0:00:36.586813\n",
      "Episode 344\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 344 completed in 0:00:54.414172\n",
      "Episode 345\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 345 completed in 0:00:52.496248\n",
      "Episode 346\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 346 completed in 0:00:39.513770\n",
      "Episode 347\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 347 completed in 0:00:47.077684\n",
      "Episode 348\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 348 completed in 0:00:51.821634\n",
      "Episode 349\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 349 completed in 0:00:43.590272\n",
      "Episode 350\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 350 completed in 0:00:35.699856\n",
      "Episode 351\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 351 completed in 0:00:52.695608\n",
      "Episode 352\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 352 completed in 0:00:31.719548\n",
      "Episode 353\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 353 completed in 0:00:41.124484\n",
      "Episode 354\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 354 completed in 0:00:56.385521\n",
      "Episode 355\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 355 completed in 0:00:35.776682\n",
      "Episode 356\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 356 completed in 0:00:43.144403\n",
      "Episode 357\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 357 completed in 0:00:31.639636\n",
      "Episode 358\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 358 completed in 0:00:46.037922\n",
      "Episode 359\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 359 completed in 0:00:40.002464\n",
      "Episode 360\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 360 completed in 0:00:50.076942\n",
      "Episode 361\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 361 completed in 0:01:04.459243\n",
      "Episode 362\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 362 completed in 0:01:06.608357\n",
      "Episode 363\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 363 completed in 0:00:39.461557\n",
      "Episode 364\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 364 completed in 0:00:49.073560\n",
      "Episode 365\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 365 completed in 0:00:40.244156\n",
      "Episode 366\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 366 completed in 0:00:40.870235\n",
      "Episode 367\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 367 completed in 0:00:54.173863\n",
      "Episode 368\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 368 completed in 0:00:52.094586\n",
      "Episode 369\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 369 completed in 0:00:51.797979\n",
      "Episode 370\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 370 completed in 0:00:57.159061\n",
      "Episode 371\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 371 completed in 0:01:11.224604\n",
      "Episode 372\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 372 completed in 0:01:02.102427\n",
      "Episode 373\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 373 completed in 0:01:08.569500\n",
      "Episode 374\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 374 completed in 0:00:47.265563\n",
      "Episode 375\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 375 completed in 0:00:39.303196\n",
      "Episode 376\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 376 completed in 0:00:55.731244\n",
      "Episode 377\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 377 completed in 0:00:39.549200\n",
      "Episode 378\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 378 completed in 0:00:40.788556\n",
      "Episode 379\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 379 completed in 0:01:05.420882\n",
      "Episode 380\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 380 completed in 0:00:35.032946\n",
      "Episode 381\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 381 completed in 0:00:43.367096\n",
      "Episode 382\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 382 completed in 0:01:01.814449\n",
      "Episode 383\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 383 completed in 0:00:34.210374\n",
      "Episode 384\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 384 completed in 0:00:38.195353\n",
      "Episode 385\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 385 completed in 0:00:37.495892\n",
      "Episode 386\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 386 completed in 0:00:48.877425\n",
      "Episode 387\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 387 completed in 0:00:28.089554\n",
      "Episode 388\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 388 completed in 0:00:48.551031\n",
      "Episode 389\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 389 completed in 0:00:35.554598\n",
      "Episode 390\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 390 completed in 0:00:57.590587\n",
      "Episode 391\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 391 completed in 0:00:38.167100\n",
      "Episode 392\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 392 completed in 0:00:46.328644\n",
      "Episode 393\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 393 completed in 0:00:34.004258\n",
      "Episode 394\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 394 completed in 0:00:45.770863\n",
      "Episode 395\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 395 completed in 0:00:56.307760\n",
      "Episode 396\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 396 completed in 0:00:33.056971\n",
      "Episode 397\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 397 completed in 0:00:41.044821\n",
      "Episode 398\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 398 completed in 0:00:28.728828\n",
      "Episode 399\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 399 completed in 0:00:48.632784\n",
      "Episode 400\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 400 completed in 0:00:42.041819\n",
      "Episode 401\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 401 completed in 0:00:25.778170\n",
      "Episode 402\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 402 completed in 0:00:37.217493\n",
      "Episode 403\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 403 completed in 0:00:57.138046\n",
      "Episode 404\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 404 completed in 0:00:24.133604\n",
      "Episode 405\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 405 completed in 0:00:43.099553\n",
      "Episode 406\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 406 completed in 0:01:01.215557\n",
      "Episode 407\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 407 completed in 0:00:46.529053\n",
      "Episode 408\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 408 completed in 0:00:27.144776\n",
      "Episode 409\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 409 completed in 0:00:42.115333\n",
      "Episode 410\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 410 completed in 0:00:46.631311\n",
      "Episode 411\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 411 completed in 0:00:28.117060\n",
      "Episode 412\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 412 completed in 0:00:28.409957\n",
      "Episode 413\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 413 completed in 0:00:44.759102\n",
      "Episode 414\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 414 completed in 0:00:37.210783\n",
      "Episode 415\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 415 completed in 0:00:52.481489\n",
      "Episode 416\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 416 completed in 0:00:39.998279\n",
      "Episode 417\n",
      "Start computing rewards based on completed FEM simulation\n",
      "24/1000\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Level 1 Warning in getfem_superlu.cc, line 217: SuperLU solve failed: info =10481\n",
      "Level 1 Warning in getfem_superlu.cc, line 217: SuperLU solve failed: info =10481\n",
      "Level 1 Warning in getfem_superlu.cc, line 217: SuperLU solve failed: info =10481\n",
      "Level 1 Warning in getfem_superlu.cc, line 217: SuperLU solve failed: info =10481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 417 completed in 0:00:54.973775\n",
      "Episode 418\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 418 completed in 0:00:45.520235\n",
      "Episode 419\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 419 completed in 0:00:36.856806\n",
      "Episode 420\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 420 completed in 0:00:48.679983\n",
      "Episode 421\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 421 completed in 0:00:32.280533\n",
      "Episode 422\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 422 completed in 0:00:44.101568\n",
      "Episode 423\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 423 completed in 0:00:57.543735\n",
      "Episode 424\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 424 completed in 0:00:35.124028\n",
      "Episode 425\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 425 completed in 0:00:54.369072\n",
      "Episode 426\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 426 completed in 0:00:44.803702\n",
      "Episode 427\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 427 completed in 0:00:51.025745\n",
      "Episode 428\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 428 completed in 0:01:01.272446\n",
      "Episode 429\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 429 completed in 0:00:58.602070\n",
      "Episode 430\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 430 completed in 0:00:42.626261\n",
      "Episode 431\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 431 completed in 0:00:46.039007\n",
      "Episode 432\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 432 completed in 0:00:42.429306\n",
      "Episode 433\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 433 completed in 0:00:46.441385\n",
      "Episode 434\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 434 completed in 0:00:32.049467\n",
      "Episode 435\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 435 completed in 0:00:46.011462\n",
      "Episode 436\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 436 completed in 0:01:00.747666\n",
      "Episode 437\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 437 completed in 0:00:47.826481\n",
      "Episode 438\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 438 completed in 0:00:45.233878\n",
      "Episode 439\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 439 completed in 0:00:46.282336\n",
      "Episode 440\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 440 completed in 0:00:32.124259\n",
      "Episode 441\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 441 completed in 0:00:56.335220\n",
      "Episode 442\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 442 completed in 0:00:34.319477\n",
      "Episode 443\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 443 completed in 0:00:52.407278\n",
      "Episode 444\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 444 completed in 0:00:53.297385\n",
      "Episode 445\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 445 completed in 0:00:41.782611\n",
      "Episode 446\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 446 completed in 0:00:44.937695\n",
      "Episode 447\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 447 completed in 0:00:32.009163\n",
      "Episode 448\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 448 completed in 0:01:03.083150\n",
      "Episode 449\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 449 completed in 0:01:03.694905\n",
      "Episode 450\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 450 completed in 0:00:57.972745\n",
      "Episode 451\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 451 completed in 0:00:33.123859\n",
      "Episode 452\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 452 completed in 0:00:30.957578\n",
      "Episode 453\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 453 completed in 0:00:51.657434\n",
      "Episode 454\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 454 completed in 0:00:45.823718\n",
      "Episode 455\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 455 completed in 0:00:54.316270\n",
      "Episode 456\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 456 completed in 0:00:48.794381\n",
      "Episode 457\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 457 completed in 0:00:43.979252\n",
      "Episode 458\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 458 completed in 0:00:48.758056\n",
      "Episode 459\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 459 completed in 0:01:08.592263\n",
      "Episode 460\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 460 completed in 0:00:53.776073\n",
      "Episode 461\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 461 completed in 0:01:07.459284\n",
      "Episode 462\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 462 completed in 0:00:56.600145\n",
      "Episode 463\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 463 completed in 0:01:13.894415\n",
      "Episode 464\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 464 completed in 0:00:37.287472\n",
      "Episode 465\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 465 completed in 0:01:05.711485\n",
      "Episode 466\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 466 completed in 0:00:45.865265\n",
      "Episode 467\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 467 completed in 0:00:48.307870\n",
      "Episode 468\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 468 completed in 0:01:00.174179\n",
      "Episode 469\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 469 completed in 0:00:51.922149\n",
      "Episode 470\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 470 completed in 0:00:43.337036\n",
      "Episode 471\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 471 completed in 0:00:34.819583\n",
      "Episode 472\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 472 completed in 0:00:40.137694\n",
      "Episode 473\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 473 completed in 0:00:40.166808\n",
      "Episode 474\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 474 completed in 0:01:03.809181\n",
      "Episode 475\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 475 completed in 0:00:33.529893\n",
      "Episode 476\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 476 completed in 0:01:01.532576\n",
      "Episode 477\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 477 completed in 0:00:52.610474\n",
      "Episode 478\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 478 completed in 0:01:07.060554\n",
      "Episode 479\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 479 completed in 0:00:31.997815\n",
      "Episode 480\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 480 completed in 0:00:31.736325\n",
      "Episode 481\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 481 completed in 0:00:30.375732\n",
      "Episode 482\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 482 completed in 0:00:49.665017\n",
      "Episode 483\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 483 completed in 0:00:57.289441\n",
      "Episode 484\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 484 completed in 0:00:28.764049\n",
      "Episode 485\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 485 completed in 0:00:54.429786\n",
      "Episode 486\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 486 completed in 0:00:28.259161\n",
      "Episode 487\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 487 completed in 0:00:37.834587\n",
      "Episode 488\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 488 completed in 0:00:45.288582\n",
      "Episode 489\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 489 completed in 0:00:44.009201\n",
      "Episode 490\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 490 completed in 0:00:44.155867\n",
      "Episode 491\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 491 completed in 0:00:54.267518\n",
      "Episode 492\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 492 completed in 0:00:50.041800\n",
      "Episode 493\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 493 completed in 0:00:36.054439\n",
      "Episode 494\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 494 completed in 0:00:50.642315\n",
      "Episode 495\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 495 completed in 0:00:33.088718\n",
      "Episode 496\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 496 completed in 0:00:38.261258\n",
      "Episode 497\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 497 completed in 0:00:48.866212\n",
      "Episode 498\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 498 completed in 0:00:46.311851\n",
      "Episode 499\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 499 completed in 0:00:47.073695\n",
      "Episode 500\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 500 completed in 0:00:44.070246\n",
      "Episode 501\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 501 completed in 0:00:31.943499\n",
      "Episode 502\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 502 completed in 0:00:29.387344\n",
      "Episode 503\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 503 completed in 0:00:56.063101\n",
      "Episode 504\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 504 completed in 0:00:40.594765\n",
      "Episode 505\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 505 completed in 0:00:36.217915\n",
      "Episode 506\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 506 completed in 0:00:56.639277\n",
      "Episode 507\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 507 completed in 0:00:39.535278\n",
      "Episode 508\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 508 completed in 0:00:39.784050\n",
      "Episode 509\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 509 completed in 0:00:36.630586\n",
      "Episode 510\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 510 completed in 0:00:45.448856\n",
      "Episode 511\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 511 completed in 0:00:55.720057\n",
      "Episode 512\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 512 completed in 0:00:52.073923\n",
      "Episode 513\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 513 completed in 0:00:31.923734\n",
      "Episode 514\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 514 completed in 0:00:52.693154\n",
      "Episode 515\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 515 completed in 0:00:33.487154\n",
      "Episode 516\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 516 completed in 0:00:36.103251\n",
      "Episode 517\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 517 completed in 0:00:43.690422\n",
      "Episode 518\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 518 completed in 0:00:44.189989\n",
      "Episode 519\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 519 completed in 0:00:35.920115\n",
      "Episode 520\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 520 completed in 0:00:58.834080\n",
      "Episode 521\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 521 completed in 0:00:30.614475\n",
      "Episode 522\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 522 completed in 0:00:31.693600\n",
      "Episode 523\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 523 completed in 0:00:37.058326\n",
      "Episode 524\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 524 completed in 0:00:49.460723\n",
      "Episode 525\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 525 completed in 0:00:36.222260\n",
      "Episode 526\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 526 completed in 0:00:34.454196\n",
      "Episode 527\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 527 completed in 0:00:43.532379\n",
      "Episode 528\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 528 completed in 0:00:31.410109\n",
      "Episode 529\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 529 completed in 0:00:49.218458\n",
      "Episode 530\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 530 completed in 0:00:52.528619\n",
      "Episode 531\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 531 completed in 0:00:54.269427\n",
      "Episode 532\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 532 completed in 0:00:22.264280\n",
      "Episode 533\n",
      "Start computing rewards based on completed FEM simulation\n",
      "31/1000\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Level 1 Warning in getfem_superlu.cc, line 217: SuperLU solve failed: info =10367\n",
      "Level 1 Warning in getfem_superlu.cc, line 217: SuperLU solve failed: info =10367\n",
      "Level 1 Warning in getfem_superlu.cc, line 217: SuperLU solve failed: info =10367\n",
      "Level 1 Warning in getfem_superlu.cc, line 217: SuperLU solve failed: info =10367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 533 completed in 0:01:06.628838\n",
      "Episode 534\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 534 completed in 0:00:52.886358\n",
      "Episode 535\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 535 completed in 0:00:40.880449\n",
      "Episode 536\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 536 completed in 0:00:57.746520\n",
      "Episode 537\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 537 completed in 0:00:51.247688\n",
      "Episode 538\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 538 completed in 0:00:51.339772\n",
      "Episode 539\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 539 completed in 0:00:26.531769\n",
      "Episode 540\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 540 completed in 0:00:32.380989\n",
      "Episode 541\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 541 completed in 0:00:33.595030\n",
      "Episode 542\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 542 completed in 0:00:50.257021\n",
      "Episode 543\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 543 completed in 0:00:36.954686\n",
      "Episode 544\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 544 completed in 0:00:35.565400\n",
      "Episode 545\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 545 completed in 0:00:49.181792\n",
      "Episode 546\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 546 completed in 0:01:18.866473\n",
      "Episode 547\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 547 completed in 0:00:52.074858\n",
      "Episode 548\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 548 completed in 0:00:35.416081\n",
      "Episode 549\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 549 completed in 0:00:52.379144\n",
      "Episode 550\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 550 completed in 0:00:50.739857\n",
      "Episode 551\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 551 completed in 0:00:51.427617\n",
      "Episode 552\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 552 completed in 0:01:07.637775\n",
      "Episode 553\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 553 completed in 0:00:38.147906\n",
      "Episode 554\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 554 completed in 0:00:55.823506\n",
      "Episode 555\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 555 completed in 0:00:48.225269\n",
      "Episode 556\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 556 completed in 0:00:31.599482\n",
      "Episode 557\n",
      "Start computing rewards based on completed FEM simulation\n",
      "30/1000\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Level 1 Warning in getfem_superlu.cc, line 217: SuperLU solve failed: info =10279\n",
      "Level 1 Warning in getfem_superlu.cc, line 217: SuperLU solve failed: info =10279\n",
      "Level 1 Warning in getfem_superlu.cc, line 217: SuperLU solve failed: info =10279\n",
      "Level 1 Warning in getfem_superlu.cc, line 217: SuperLU solve failed: info =10279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 557 completed in 0:01:02.820882\n",
      "Episode 558\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 558 completed in 0:00:52.350367\n",
      "Episode 559\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 559 completed in 0:00:37.566721\n",
      "Episode 560\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 560 completed in 0:00:53.159959\n",
      "Episode 561\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 561 completed in 0:00:56.824520\n",
      "Episode 562\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 562 completed in 0:00:36.921134\n",
      "Episode 563\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 563 completed in 0:00:32.932789\n",
      "Episode 564\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 564 completed in 0:00:42.676298\n",
      "Episode 565\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 565 completed in 0:00:31.600945\n",
      "Episode 566\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 566 completed in 0:00:48.447543\n",
      "Episode 567\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 567 completed in 0:00:43.388297\n",
      "Episode 568\n",
      "Start computing rewards based on completed FEM simulation\n",
      "26/1000\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Level 1 Warning in getfem_superlu.cc, line 217: SuperLU solve failed: info =10457\n",
      "Level 1 Warning in getfem_superlu.cc, line 217: SuperLU solve failed: info =10457\n",
      "Level 1 Warning in getfem_superlu.cc, line 217: SuperLU solve failed: info =10457\n",
      "Level 1 Warning in getfem_superlu.cc, line 217: SuperLU solve failed: info =10457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 568 completed in 0:01:03.541960\n",
      "Episode 569\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 569 completed in 0:01:06.913614\n",
      "Episode 570\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 570 completed in 0:00:44.235814\n",
      "Episode 571\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 571 completed in 0:00:43.512216\n",
      "Episode 572\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 572 completed in 0:00:35.870264\n",
      "Episode 573\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 573 completed in 0:00:33.499247\n",
      "Episode 574\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 574 completed in 0:00:52.303651\n",
      "Episode 575\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 575 completed in 0:00:35.681980\n",
      "Episode 576\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 576 completed in 0:00:50.056549\n",
      "Episode 577\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 577 completed in 0:00:27.105322\n",
      "Episode 578\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 578 completed in 0:00:30.588743\n",
      "Episode 579\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 579 completed in 0:00:34.063588\n",
      "Episode 580\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 580 completed in 0:00:47.545000\n",
      "Episode 581\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 581 completed in 0:00:36.366365\n",
      "Episode 582\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 582 completed in 0:00:51.245858\n",
      "Episode 583\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 583 completed in 0:00:35.872531\n",
      "Episode 584\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 584 completed in 0:01:05.386873\n",
      "Episode 585\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 585 completed in 0:01:12.638958\n",
      "Episode 586\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 586 completed in 0:00:50.836698\n",
      "Episode 587\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 587 completed in 0:00:38.382418\n",
      "Episode 588\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 588 completed in 0:00:51.069700\n",
      "Episode 589\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 589 completed in 0:00:35.137026\n",
      "Episode 590\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 590 completed in 0:00:38.640951\n",
      "Episode 591\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 591 completed in 0:00:46.532192\n",
      "Episode 592\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 592 completed in 0:00:53.436979\n",
      "Episode 593\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 593 completed in 0:00:50.653687\n",
      "Episode 594\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 594 completed in 0:00:29.366529\n",
      "Episode 595\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 595 completed in 0:01:07.474199\n",
      "Episode 596\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 596 completed in 0:00:37.905202\n",
      "Episode 597\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 597 completed in 0:00:50.498436\n",
      "Episode 598\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 598 completed in 0:00:46.646234\n",
      "Episode 599\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 599 completed in 0:00:53.197063\n",
      "Episode 600\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 600 completed in 0:00:44.412727\n",
      "Episode 601\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 601 completed in 0:00:30.117288\n",
      "Episode 602\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 602 completed in 0:00:51.303358\n",
      "Episode 603\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 603 completed in 0:00:50.251953\n",
      "Episode 604\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 604 completed in 0:00:40.339410\n",
      "Episode 605\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 605 completed in 0:00:35.816971\n",
      "Episode 606\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 606 completed in 0:00:49.424714\n",
      "Episode 607\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 607 completed in 0:00:41.313449\n",
      "Episode 608\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 608 completed in 0:00:56.049576\n",
      "Episode 609\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 609 completed in 0:00:49.291530\n",
      "Episode 610\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 610 completed in 0:00:30.450285\n",
      "Episode 611\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 611 completed in 0:01:14.326548\n",
      "Episode 612\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 612 completed in 0:00:39.423070\n",
      "Episode 613\n",
      "Start computing rewards based on completed FEM simulation\n",
      "Episode 613 completed in 0:00:55.137890\n",
      "Episode 614\n",
      "Start computing rewards based on completed FEM simulation\n",
      "46/1000\r"
     ]
    }
   ],
   "source": [
    "#print(agent.generate())\n",
    "\n",
    "agent.train(1000)\n",
    "\n",
    "#print(agent.generate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(list(range(len(agent.running_loss))), agent.running_loss, s=1, vmin=0, vmax=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manuscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = str(123)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1, 2])\n",
    "b = torch.tensor([1, 2])\n",
    "torch.equal(a, b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_stat: Dict[str, int] = {'solved': 0, 'image_cache': 0, 'file_cache': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "r = torch.cuda.memory_reserved(0)\n",
    "a = torch.cuda.memory_allocated(0)\n",
    "f = r-a  # free inside reserved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyRL3.10",
   "language": "python",
   "name": "pyrl3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "neptune": {
   "notebookId": "45d03d69-6ac7-41ca-8af8-80caaa73aad5",
   "projectVersion": 2
  },
  "toc-autonumbering": false,
  "toc-showtags": false,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
